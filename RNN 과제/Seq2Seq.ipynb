{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyN+r98CfN3PyRDoq/PJ24uy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Seq2Seq\n","\n","이름 :\n","\n","기수 :\n","\n","작성자 : 10 기 신재우"],"metadata":{"id":"81OmhkOjsQE2"}},{"cell_type":"code","source":["# colab 환경에서 학습을 진행하실 분들은 구글드라이브를 연동해주세요\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDsAaMpW9BRN","executionInfo":{"status":"ok","timestamp":1708328561050,"user_tz":-540,"elapsed":15827,"user":{"displayName":"Jae Woo Shin","userId":"00227897202452450211"}},"outputId":"bfbd518a-36d0-4fd7-b98d-d9cce543c778"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### 시작 전 실행할 것들"],"metadata":{"id":"tMoeOKFOUSyM"}},{"cell_type":"code","source":["%pip install konlpy"],"metadata":{"id":"vgHcwMYXUWPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Kkma\n","from konlpy.utils import pprint\n","import pandas as pd\n","import numpy as np\n","import tqdm\n","import spacy\n","import torchtext\n","import torch\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import random\n","import os\n","from ast import literal_eval\n","import torchtext.vocab as vocab\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence"],"metadata":{"id":"qmKTJoWnUW-z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 경로 설정"],"metadata":{"id":"amrKyxSjUZC8"}},{"cell_type":"code","source":["path_to_folder = \"/content/drive/MyDrive/DSL/세션 준비/과제/RNN + Transformers\""],"metadata":{"id":"O2xMP9UiUaMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_train = os.path.join(path_to_folder, \"Dataset/train_dataset_Tokenized.csv\")\n","path_val = os.path.join(path_to_folder, \"Dataset/val_dataset_Tokenized.csv\")\n","path_test = os.path.join(path_to_folder, \"Dataset/test_dataset_Tokenized.csv\")\n","train_dataset = pd.read_csv('/content/drive/MyDrive/DSL/세션 준비/과제/RNN + Transformers/Dataset/train_dataset_Vocabulary.csv', index_col = 0)\n","val_dataset = pd.read_csv('/content/drive/MyDrive/DSL/세션 준비/과제/RNN + Transformers/Dataset/val_dataset_Vocabulary.csv', index_col = 0)\n","test_dataset = pd.read_csv('/content/drive/MyDrive/DSL/세션 준비/과제/RNN + Transformers/Dataset/test_dataset_Vocabulary.csv', index_col = 0)"],"metadata":{"id":"SLHgX-1rVS94"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vocabulary"],"metadata":{"id":"U1txZ6oZURkU"}},{"cell_type":"code","source":["train_dataset['en_tokens'] = train_dataset['en_tokens'].apply(literal_eval)\n","train_dataset['kr_tokens'] = train_dataset['kr_tokens'].apply(literal_eval)\n","\n","val_dataset['en_tokens'] = val_dataset['en_tokens'].apply(literal_eval)\n","val_dataset['kr_tokens'] = val_dataset['kr_tokens'].apply(literal_eval)\n","\n","test_dataset['en_tokens'] = test_dataset['en_tokens'].apply(literal_eval)\n","test_dataset['kr_tokens'] = test_dataset['kr_tokens'].apply(literal_eval)\n","\n","train_dict = train_dataset.to_dict(orient = 'records')\n","val_dict = val_dataset.to_dict(orient = 'records')\n","test_dict = test_dataset.to_dict(orient = 'records')"],"metadata":{"id":"HmoRdiSuVcPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_freq = 2\n","unk_token = \"<unk>\"\n","pad_token = \"<pad>\"\n","sos_token = \"<sos>\"\n","eos_token = \"<eos>\"\n","\n","special_tokens = [\n","    unk_token,\n","    pad_token,\n","    sos_token,\n","    eos_token,\n","]"],"metadata":{"id":"5cxOusSKVeZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def yield_tokens(data, token_field):\n","    for item in data:\n","        yield item[token_field]\n","\n","en_vocab = vocab.build_vocab_from_iterator(\n","    yield_tokens(train_dict, \"en_tokens\"),\n","    specials=special_tokens,\n","    min_freq=min_freq\n",")\n","\n","kr_vocab = vocab.build_vocab_from_iterator(\n","    yield_tokens(train_dict, \"kr_tokens\"),\n","    specials=special_tokens,\n","    min_freq=min_freq\n",")\n","\n","en_vocab.set_default_index(en_vocab[unk_token])\n","kr_vocab.set_default_index(kr_vocab[unk_token])"],"metadata":{"id":"feSCoByRVkic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size_en = len(en_vocab)\n","vocab_size_kr = len(kr_vocab)\n","print(\"English Vocabulary Length : \", vocab_size_en)\n","print(\"Korean Vocabulary Length : \", vocab_size_kr)"],"metadata":{"id":"NbT8BsNEVrKo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 문제 2 (Vocabulary Matching)\n","\n","토큰화된 단어들을 Vocabulary 과 매칭 시켜서 **벡터**로 바꿔준 뒤에 **텐서**로 바꿔주는 단계까지 포함되어야 합니다!"],"metadata":{"id":"PHBCH3yrVx_d"}},{"cell_type":"markdown","source":["힌트 :\n","\n","- $\\texttt{en_vocab.lookup_indices}$, 혹은 $\\texttt{kr_vocab.lookup_indices}$\n","- 한줄로 표현이 가능합니다!\n","- en_indices 와 kr_indices 는 리스트이며, 텐서화 된 것들을 각 토큰마다 리스트로 가져야 합니다!"],"metadata":{"id":"uOTpst0tUGl4"}},{"cell_type":"code","source":["en_indices = []\n","for word in train_dataset['en_tokens']:\n","  ___\n","\n","train_dataset['en_indices'] = en_indices\n","\n","kr_indices = []\n","for word in train_dataset['kr_tokens']:\n","  ___\n","\n","train_dataset['kr_indices'] = kr_indices"],"metadata":{"id":"h0js3rbPVzFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_indices = []\n","for word in val_dataset['en_tokens']:\n","  ___\n","\n","val_dataset['en_indices'] = en_indices\n","\n","kr_indices = []\n","for word in val_dataset['kr_tokens']:\n","  ___\n","\n","val_dataset['kr_indices'] = kr_indices"],"metadata":{"id":"717Y-36Rlf5U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_indices = []\n","for word in test_dataset['en_tokens']:\n","  ___\n","\n","test_dataset['en_indices'] = en_indices\n","\n","kr_indices = []\n","for word in test_dataset['kr_tokens']:\n","  ___\n","\n","test_dataset['kr_indices'] = kr_indices"],"metadata":{"id":"YCTSyQuulg-u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loaders"],"metadata":{"id":"fCMEG6qrV-YX"}},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, dataframe):\n","        self.dataframe = dataframe\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        item = self.dataframe.iloc[idx]\n","        en_indices = item['en_indices']\n","        kr_indices = item['kr_indices']\n","        return en_indices, kr_indices"],"metadata":{"id":"gD6Z8IpgV_kO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_no = 80\n","\n","def collate_fn(batch):\n","    en_indices, kr_indices = zip(*batch)\n","    en_indices_padded = pad_sequence(en_indices, batch_first=True, padding_value=0)\n","    kr_indices_padded = pad_sequence(kr_indices, batch_first=True, padding_value=0)\n","\n","    return en_indices_padded, kr_indices_padded\n","\n","train_custom_dataset = CustomDataset(train_dataset[['en_indices', 'kr_indices']])\n","val_custom_dataset = CustomDataset(val_dataset[['en_indices', 'kr_indices']])\n","test_custom_dataset = CustomDataset(test_dataset[['en_indices', 'kr_indices']])\n","\n","train_loader = DataLoader(train_custom_dataset, batch_size=batch_no, shuffle=True, collate_fn=collate_fn)\n","val_loader = DataLoader(val_custom_dataset, batch_size=batch_no, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(test_custom_dataset, batch_size=batch_no, shuffle=True, collate_fn=collate_fn)"],"metadata":{"id":"Lnk1JKUBWGXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_collate_fn(pad_index):\n","    def collate_fn(batch):\n","        batch_en_ids = [example[\"en_indices\"] for example in batch]\n","        batch_de_ids = [example[\"de_indices\"] for example in batch]\n","        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n","        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n","        batch = {\n","            \"en_ids\": batch_en_ids,\n","            \"de_ids\": batch_de_ids,\n","        }\n","        return batch\n","\n","    return collate_fn\n","\n","def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n","    collate_fn = get_collate_fn(pad_index)\n","    data_loader = torch.utils.data.DataLoader(\n","        dataset=dataset,\n","        batch_size=batch_size,\n","        collate_fn=collate_fn,\n","        shuffle=shuffle,\n","    )\n","    return data_loader"],"metadata":{"id":"7wvbZByNWJx7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 잘 매칭이 되었는지 확인해보기!"],"metadata":{"id":"TFgkHCI9tm3W"}},{"cell_type":"code","source":["for i, (en_indices, kr_indices) in enumerate(train_loader):\n","    print(f\"Batch {i+1}\")\n","    print(f\"Shape of en_indices: {en_indices.shape}\")\n","    print(f\"Shape of kr_indices: {kr_indices.shape}\")\n","\n","    print(\"Sample en_indices batch:\", en_indices[:1])\n","    print(\"Sample kr_indices batch:\", kr_indices[:1])\n","\n","    if i == 1:\n","        break"],"metadata":{"id":"ZVpBnanAWLcu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 문제 3 (Modules without Attention!)\n","\n","기본적인 Seq2seq 모듈들은 Teacher Forcing 까지 포함해서 진행해주시길 바랍니다."],"metadata":{"id":"Km8VwlCHWpiT"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  \"\"\"\n","  Encoder 내에서는 Input Language 의 Vocab 크기, Embedding 크기, Hidden 크기가 들어갑니다.\n","\n","  Embedding 과정에서 Input 크기 --> Embedding 크기 로 진행됩니다.\n","  GRU 내에서는 Embedding 크기 --> Hidden 크기 로 진행됩니다.\n","\n","  Input : [Batch_size, Input Sequences Max Size]\n","  Output : [Batch_size, Input Sequences Max Size, Hidden Size]\n","  Hidden : [1, Batch_size, Hidden Size]\n","\n","  힌트 :\n","  - Batch 가 앞에 있기 때문에 GRU 는 batch_first = True 라는 파라미터를 설정해줘야 합니다.\n","  - GRU 에서는 Output, Hidden Vector, 총 2개를 뱉어줍니다.\n","  - GRU 는 nn.GRU, Embedder 는 nn.Embedding 를 사용해주면 됩니다.\n","  \"\"\"\n","  def __init__(self, input_size, embedding_encoder_size, hidden_size):\n","    super().__init__()\n","\n","\n","\n","\n","\n","  def forward(self, input):\n","\n","\n","\n","\n","\n","    return output, hidden"],"metadata":{"id":"Lpw6roQsWqH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","  \"\"\"\n","  Decoder 내에서는 Hidden 크기, Embedding Decoder 크기 (Embedding Encoder 크기와 동일), Output Language 의 Vocab 의 크기가 들어갑니다.\n","\n","  Embedding 과정에서 Output 크기 --> Embedding 크기 로 진행됩니다.\n","  GRU 내에서는 Embedding 크기 --> Hidden 크기 로 진행됩니다.\n","  Linear 내에서는 Hidden 크기 --> Output 크기 로 진행됩니다.\n","\n","  Teacher Forcing 은 디코더를 구성하는 코드에서는 고려를 안해도 되며, 나중에 Seq2Seq 모듈에서 진행해주시길 바랍니다.\n","\n","  Input 과 Hidden 크기의 경우 Seq2Seq 모듈 내에서 차원을 맞춰주시면 됩니다.\n","  \"\"\"\n","  def __init__(self, hidden_size, embedding_decoder_size, output_size):\n","    super().__init__()\n","\n","\n","\n","\n","\n","  def forward(self, input, hidden):\n","\n","\n","\n","\n","\n","    return preds, hidden"],"metadata":{"id":"O0x0Bp-TWyvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","  \"\"\"\n","  Seq2Seq 내에서는 Encoder, Decoder, Device 가 들어갑니다.\n","\n","  Init 단계에서는 정말로 할 것이 크게 없으며, forward 단계에서 for loop 과 if 조건문들을 활용해서 Teacher Forcing 을 적용시켜주면 됩니다.\n","\n","  Input : [Batch_size, Input Sequences Max Size]\n","  Target : [Batch_size, Target Sequences Max Size]\n","  Output : [Batch_size, Input Sequences Max Size, Input Language Vocab Size]\n","\n","  힌트 :\n","  - outputs 란 0 으로 채워진 텐서를 하나 만들며 디코더의 t-번째 아웃풀을 outputs 의 t-번째 칸에 넣으면서 for loop 을 진행해주시면 됩니다.\n","  - Target 의 첫번째 요소 (:, 0) 는 항상 <sos> 입니다! 이것을 디코더의 첫 Input 으로 넣어준 다음에 for loop 을 진행해주시면 됩니다.\n","  - random.random() < teacher_forcing_ratio 를 통해서 조건문을 만들 수가 있습니다!\n","  - Teacher Force 가 적용이 안될 때는디코더의 아웃풋에는 모든 토큰들에 대한 점수가 나오게 됩니다.\n","    이것들 중에서 가장 최댓값만 중요하기에 argmax 를 이용해서 최댓값의 인덱스를 다음 Decoder 의 Input 으로 넣어주면 됩니다.\n","  - squeeze 와 unsqueeze 를 적극적으로 활용해서 차원을 조정해주시면 됩니다!\n","  \"\"\"\n","  def __init__(self, encoder, decoder, device):\n","    super().__init__()\n","\n","\n","\n","\n","\n","  def forward(self, input, target, teacher_forcing_ratio = 0.5):\n","\n","\n","\n","\n","\n","    return"],"metadata":{"id":"XKUZiixvW9XL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"A-CoqD6RXE0A"}},{"cell_type":"code","source":["input_dim = len(en_vocab)\n","output_dim = len(kr_vocab)\n","encoder_embedding_dim = 512\n","decoder_embedding_dim = 512\n","hidden_dim = 1024\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","encoder = Encoder(input_dim, encoder_embedding_dim, hidden_dim)\n","decoder = Decoder(hidden_dim, decoder_embedding_dim, output_dim)\n","model = Seq2Seq(encoder, decoder, device).to(device)"],"metadata":{"id":"LK_MEUcYXFWJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 모델 확인 + Initialize 시키기"],"metadata":{"id":"S-segCKDdQ9b"}},{"cell_type":"code","source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)\n","\n","model.apply(init_weights)\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"The model has {count_parameters(model):,} trainable parameters\")"],"metadata":{"id":"mwT13TE-dSEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 하이퍼 파라미터 설정!"],"metadata":{"id":"06iMvjqtdpEY"}},{"cell_type":"code","source":["unk_index = en_vocab[unk_token]\n","pad_index = en_vocab[pad_token]\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n","\n","n_epochs = 10\n","teacher_forcing_ratio = 0.5"],"metadata":{"id":"1V6JMwl4dVed"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training 코드!"],"metadata":{"id":"MGkVj7Psdxq6"}},{"cell_type":"code","source":["for epoch in range(n_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    for (en_indices, kr_indices) in train_loader:\n","        en_indices, kr_indices = en_indices.to(device), kr_indices.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(en_indices, kr_indices[:, :-1], teacher_forcing_ratio)  # Target 에서는 <eos> 는 무시하고 진행합니다.\n","        output_dim = output.shape[-1]\n","\n","        output = output.contiguous().view(-1, output_dim)\n","\n","        kr_indices = kr_indices[:, 1:].contiguous().view(-1)  # Target 에서 <sos> 를 무시하기 위함입니다.\n","\n","        loss = criterion(output, kr_indices)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    train_loss = epoch_loss\n","\n","    model.eval()\n","    epoch_loss = 0\n","    with torch.no_grad():\n","      for (en_indices, kr_indices) in val_loader:\n","        en_indices, kr_indices = en_indices.to(device), kr_indices.to(device)\n","\n","        output = model(en_indices, kr_indices[:, :-1], teacher_forcing_ratio = 0.0)\n","        output_dim = output.shape[-1]\n","\n","        output = output.contiguous().view(-1, output_dim)\n","        kr_indices = kr_indices[:, 1:].contiguous().view(-1)\n","\n","        loss = criterion(output, kr_indices)\n","        epoch_loss += loss.item()\n","\n","    print(f'Epoch: {epoch+1}, Train Loss : {train_loss / len(train_loader)}, Val Loss: {epoch_loss / len(val_loader)}')"],"metadata":{"id":"JRHvl3Vhdznr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["파라미터 저장"],"metadata":{"id":"Z43rSKG8oxYT"}},{"cell_type":"code","source":["path_to_save = os.path.join(path_to_folder, \"model_without_attention.pt\")\n","torch.save(model.state_dict(), path_to_save)"],"metadata":{"id":"fZUaumJ0owRa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 적용시켜보기"],"metadata":{"id":"aFE0k364pflN"}},{"cell_type":"code","source":["test_batch_en, test_batch_kr = next(iter(test_loader))\n","test_en = test_batch_en[0].numpy()\n","test_kr = test_batch_kr[0].numpy()\n","model.eval()\n","with torch.no_grad():\n","  output = model(test_batch_en.to(device), test_batch_kr.to(device)[:, :-1], teacher_forcing_ratio = 0.0)\n","  print(en_vocab.lookup_tokens(test_en))\n","  print(kr_vocab.lookup_tokens(test_kr))\n","  print(kr_vocab.lookup_tokens(output.argmax(2).cpu().numpy()[0]))"],"metadata":{"id":"TnWK13NTphiL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\\<unk\\> 는 저희 Vocabulary 에는 존재하지 않는 토큰들을 의미합니다."],"metadata":{"id":"vic3YSmcTVJF"}},{"cell_type":"markdown","source":["아무리 epoch 를 늘리거나 무엇을 해보려고 해도 완전히 좋은 결과가 나오지는 않을 것입니다. 해당 이유는 Attention 이 적용이 안되었기 때문이며, 다음과 같이 Attention 을 적용시켜서 한번 진행하면 결과가 다르다는 것을 알 수가 있습니다."],"metadata":{"id":"2kCwetjJpi7v"}},{"cell_type":"markdown","source":["# 문제 4 (Modules WITH Attention)\n","\n","만약에 메모리가 다 찼다면 해당 Run 을 Reconnect 시켜서 위의 Output 만 남긴 채로 제출하시면 됩니다.\n","\n","**이렇게 진행하게 된다면 당연히 문제 3 이전의 코드들은 다시 돌려야 됩니다!!**"],"metadata":{"id":"Baj4ccKLpA7f"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  \"\"\"\n","  이전과 Encoder 부분은 달라지는게 없습니다!\n","  \"\"\"\n","  def __init__(self, input_size, embedding_encoder_size, hidden_size):\n","\n","\n","\n","  def forward(self, input):\n","\n","\n","    return"],"metadata":{"id":"XEsWf5llpGTs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Attention(nn.Module):\n","  \"\"\"\n","  해당 모듈에서는 Attention Value 까지 찾는 단계입니다.\n","\n","  Encoder 내에서의 Output 들의 개수마다 for loop 을 진행시켜서 합산시켜서 Attention Value 를 구하는 방법도 있지만,\n","  Encoder Output 들을 모두 Matrix 으로 표현해서 구하는 방법도 있습니다.\n","\n","  Decoder_Outputs : [Batch_size, 1, Hidden_size]\n","  Encoder_Outputs : [Batch_size, Sequence Length, Hidden_size]\n","\n","  힌트 :\n","  - Decoder_Outputs 의 차원이 위와 같이 안 나온다면 차원 조정을 위해서 squeeze, unsqueeze, transpose 등의 함수들을 활용해주면 됩니다.\n","  - Matrix Multiplication 을 진행할 때에 Batch 까지 곱해지는 것을 방지하기 위해서 torch.bmm(x, y) 를 활용해주면 됩니다.\n","  - 곱해줄 때에는 그저 x * y 를 해주면 됩니다.\n","  - 합산할 때에는 배치도 고려해야 함으로 torch.sum(x, dim = 1) 을 활용해주면 됩니다.\n","  - 해당 모듈 내에서 필요한 nn. 함수는 오로지 Softmax 밖에 없습니다.\n","  \"\"\"\n","\n","  def __init__(self, hidden_size):\n","\n","\n","  def forward(self, decoder_outputs, encoder_outputs):\n","\n","\n","\n","    return"],"metadata":{"id":"jWbH174Ep0h9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","  \"\"\"\n","  Attention Value 를 Attention 모듈을 통해서 구했기 때문에 Concatenate, Tangent Hyperbolic 등의 것들이 여기에서 적용이 됩니다.\n","\n","  힌트 :\n","  - 모든 것을 진행하기 전에 앞서서 먼저 GRU 를 지나고 나서 Output 을 활용해야 합니다.\n","  - Attention 모듈도 사용해야 하기 때문에 해당 모듈을 현 모듈에서 정의도 해줘야 합니다.\n","  - Concatenate 의 경우 torch.cat((x, y), dim = 1) 형태로 사용하면 됩니다.\n","  - W_c 와 v_t 를 곱해줄 때 W_c 는 가중치 행렬이며, 이것은 그저 nn.Linear 형태로 표현이 가능합니다.\n","  \"\"\"\n","  def __init__(self, hidden_size, embedding_decoder_size, output_size):\n","    super().__init__()\n","\n","\n","\n","\n","\n","  def forward(self, input, hidden, encoder_outputs):\n","\n","\n","\n","\n","\n","    return"],"metadata":{"id":"XCWOd398pHjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","  \"\"\"\n","  이전과 Seq2Seq 부분은 크게 달라지는게 없습니다!\n","  단지 디코더가 Input 을 하나 더 받기 때문에 조심해주시길 바랍니다.\n","  \"\"\"\n","  def __init__(self, encoder, decoder):\n","    super().__init__()\n","\n","\n","\n","\n","\n","  def forward(self, input, target, teacher_forcing_ratio = 0.5):\n","\n","\n","\n","\n","\n","    return"],"metadata":{"id":"Tb0V7475pIqs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"J0llq92EpKax"}},{"cell_type":"code","source":["input_dim = len(en_vocab)\n","output_dim = len(kr_vocab)\n","encoder_embedding_dim = 512\n","decoder_embedding_dim = 512\n","hidden_dim = 1024\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","encoder = Encoder(input_dim, encoder_embedding_dim, hidden_dim)\n","decoder = Decoder(hidden_dim, decoder_embedding_dim, output_dim)\n","model = Seq2Seq(encoder, decoder, device).to(device)"],"metadata":{"id":"bFtRh32MpLm-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 모델 확인 + Initialize 시키기"],"metadata":{"id":"9hiwDoXRpPIg"}},{"cell_type":"code","source":["model.apply(init_weights)\n","print(f\"The model has {count_parameters(model):,} trainable parameters\")"],"metadata":{"id":"iGQf0te0pRMs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 하이퍼 파라미터 설정!"],"metadata":{"id":"nn5w6exHpVXE"}},{"cell_type":"code","source":["unk_index = en_vocab[unk_token]\n","pad_index = en_vocab[pad_token]\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n","\n","n_epochs = 10\n","teacher_forcing_ratio = 0.5"],"metadata":{"id":"jd88dcNJpXFt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 학습 시키기!"],"metadata":{"id":"yirBt0VZpY0R"}},{"cell_type":"code","source":["for epoch in range(n_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    for (en_indices, kr_indices) in train_loader:\n","        en_indices, kr_indices = en_indices.to(device), kr_indices.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(en_indices, kr_indices[:, :-1], teacher_forcing_ratio)  # Target 에서는 <eos> 는 무시하고 진행합니다.\n","        output_dim = output.shape[-1]\n","\n","        output = output.contiguous().view(-1, output_dim)\n","\n","        kr_indices = kr_indices[:, 1:].contiguous().view(-1)  # Target 에서 <sos> 를 무시하기 위함입니다.\n","\n","        loss = criterion(output, kr_indices)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    train_loss = epoch_loss\n","    model.eval()\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","      for (en_indices, kr_indices) in val_loader:\n","        en_indices, kr_indices = en_indices.to(device), kr_indices.to(device)\n","\n","        output = model(en_indices, kr_indices[:, :-1], teacher_forcing_ratio = 0.0)\n","        output_dim = output.shape[-1]\n","\n","        output = output.contiguous().view(-1, output_dim)\n","        kr_indices = kr_indices[:, 1:].contiguous().view(-1)\n","\n","        loss = criterion(output, kr_indices)\n","        epoch_loss += loss.item()\n","    print(f'Epoch: {epoch+1}, Train Loss : {train_loss / len(train_loader)}, Val Loss: {epoch_loss / len(val_loader)}')"],"metadata":{"id":"bv30DvqupaDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 파라미터 저장"],"metadata":{"id":"DunzKpsxpcQ1"}},{"cell_type":"code","source":["path_to_save = os.path.join(path_to_folder, \"model_WITH_attention.pt\")\n","torch.save(model.state_dict(), path_to_save)"],"metadata":{"id":"cGKqGRwApdjq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 적용시켜보기"],"metadata":{"id":"oMx032StsKGQ"}},{"cell_type":"code","source":["test_batch_en, test_batch_kr = next(iter(train_loader))\n","test_en = test_batch_en[0].numpy()\n","test_kr = test_batch_kr[0].numpy()\n","model.eval()\n","with torch.no_grad():\n","  output = model(test_batch_en.to(device), test_batch_kr.to(device)[:, :-1], teacher_forcing_ratio = 0.0)\n","  print(en_vocab.lookup_tokens(test_en))\n","  print(kr_vocab.lookup_tokens(test_kr))\n","  print(kr_vocab.lookup_tokens(output.argmax(2).cpu().numpy()[0]))"],"metadata":{"id":"N6dCZzyPsL21"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["아마 결과가 온전히 잘 나오지는 않을 겁입니다. 해당 이유는 단순히 파라미터 개수가 적기 때문이며, 잘 나오기 위해서는 이보다 훨씬 늘려야 합니다. 원하신다면 Hidden_size, Embedding_size 를 늘려서 진행하는 것도 가능하긴 합니다!"],"metadata":{"id":"bSej04HcTfpk"}},{"cell_type":"markdown","source":["과제 하시느라 정말로 고생하셨습니다!"],"metadata":{"id":"B0fp8B_nsMde"}}]}